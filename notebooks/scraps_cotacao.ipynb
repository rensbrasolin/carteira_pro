{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "010a7198",
   "metadata": {},
   "source": [
    "# Cotação\n",
    "\n",
    "- Fxs que eu trouxe intactas (sem testar) do antigo projeto web1\n",
    "- Caso precise no futuro, já tenho um ponto de partida.\n",
    "- Prefri trazê-las para um NB, assim fica mais fácil testar antes de passar para o projeto.\n",
    "- Diferente da fx que uso no app atualmente (tvb3), nessas aqui passo um df como argumento (que precisa ser criado antes de chamar a fx). Até porque algumas delas precisam do tipo de ativo para raspar, pois os tipos estarão em lugares diferentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7f2fc8",
   "metadata": {},
   "source": [
    "### Info Money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ed8f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algumas poucas urls de tickers não são encontradas. Entre elas GARE11 e ISAE4 que tiveram troca de ticker recentemente.\n",
    "# Então acredito ser algum problema da base do próprio site.\n",
    "# Funciona local e na nuvem.\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "\n",
    "def criar_df_cotacao_infomoney(df_mov_financeiras):\n",
    "\n",
    "    # Obtendo os valores únicos da coluna 'Ativo' e 'Tipo de Ativo' e convertendo em uma lista de listas\n",
    "    lista_tickers = df_mov_financeiras[['Ativo', 'Tipo de Ativo']].drop_duplicates().values.tolist()\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": \"https://www.infomoney.com.br/\"\n",
    "    }\n",
    "\n",
    "    dados = []\n",
    "\n",
    "    for ticker, tipo in lista_tickers:\n",
    "\n",
    "        # É estranho pois a url é assim: https://www.infomoney.com.br/cotacoes/b3/acao/banco-do-brasil-bbas3/\n",
    "        # Mas eu requisitando a url assim, eu tbm chego no endereço acima: https://www.infomoney.com.br/bbas3/\n",
    "        url = f\"https://www.infomoney.com.br/{ticker.lower()}\"\n",
    "\n",
    "        valor = None\n",
    "\n",
    "        if url:\n",
    "            try:\n",
    "                response = requests.get(url, headers=headers, timeout=10)\n",
    "                response.raise_for_status()\n",
    "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "                # Escolhendo a classe correta com base no tipo de ativo\n",
    "                if tipo == 'Ação' or tipo == 'ETF':\n",
    "                    cotacao_elemento = soup.find(\"div\", class_=\"value\")\n",
    "                    texto_bruto = cotacao_elemento.get_text(strip=True)\n",
    "                    texto = texto_bruto[0:5]\n",
    "                    valor = float(texto.replace(\"R$\", \"\").replace(\".\", \"\").replace(\",\", \".\"))\n",
    "                elif tipo == 'FII':\n",
    "                    cotacao_elemento = soup.find(\"span\", class_=\"typography__display--2-noscale typography--numeric spacing--mr1\")\n",
    "                    texto = cotacao_elemento.get_text(strip=True)\n",
    "                    valor = float(texto.replace(\"R$\", \"\").replace(\".\", \"\").replace(\",\", \".\"))\n",
    "                else:\n",
    "                    cotacao_elemento = None  # Tipo indefinido, não procuramos\n",
    "                    print(f\"Cotação não encontrada para {ticker} na URL: {url}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao obter {ticker} na URL: {url} | Erro: {e}\")\n",
    "\n",
    "            # Adicionando à lista de dados para o DataFrame\n",
    "            dados.append({\n",
    "                \"Ticker\": ticker,\n",
    "                \"Preço\": valor\n",
    "            })\n",
    "\n",
    "            sleep(1)  # pausa para evitar bloqueio\n",
    "\n",
    "    return pd.DataFrame(dados)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "## Código para investigar formas de obter o arquivo através de NAME e CLASS\n",
    "\n",
    "# import requests\n",
    "# import pandas as pd\n",
    "# from bs4 import BeautifulSoup\n",
    "# from time import sleep\n",
    "#\n",
    "# headers = {\n",
    "#     \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36\",\n",
    "#     \"Referer\": \"https://www.infomoney.com.br/\"\n",
    "# }\n",
    "#\n",
    "# # É estranho pois a url é assim: https://www.infomoney.com.br/cotacoes/b3/acao/banco-do-brasil-bbas3/\n",
    "# # Mas eu requisitando a url assim, eu tbm chego no endereço acima: https://www.infomoney.com.br/bbas3/\n",
    "# url = \"https://www.infomoney.com.br/vale3\"\n",
    "#\n",
    "# response = requests.get(url, headers=headers, timeout=10)\n",
    "#\n",
    "# soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "#\n",
    "# # Procurar o elemento que contém a cotação (div com classe \"value\")\n",
    "# cotacao_elemento = soup.find(\"div\", class_=\"value\") # classe para fiis=\"cotacoes__header-price\" , ações e etfs \"value\"\n",
    "#\n",
    "# # soup\n",
    "#\n",
    "# cotacao_elemento\n",
    "#\n",
    "# texto = cotacao_elemento.get_text(strip=True)\n",
    "#\n",
    "#\n",
    "# texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9e5034",
   "metadata": {},
   "source": [
    "### Investidor 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d363d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por enquanto funciona local e na nuvem\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "\n",
    "def criar_df_cotacao_investidor10(df_mov_financeiras):\n",
    "    \"\"\"\n",
    "    Função para buscar a cotação atual de uma lista de ativos no site Investidor10.\n",
    "    A URL e classe do html acessada dependem do tipo de ativo: Ação, FII ou ETF.\n",
    "    Classes para puxar elemento:\n",
    "        Descobri a classe pelo cod fonte, dando CTRL+f e pesquisando cotação = da página. Lá peguei a classe.\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtendo os valores únicos da coluna 'Ativo' e 'Tipo de Ativo' e convertendo em uma lista de listas\n",
    "    lista_tickers = df_mov_financeiras[['Ativo', 'Tipo de Ativo']].drop_duplicates().values.tolist()\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": \"https://investidor10.com.br\"\n",
    "    }\n",
    "\n",
    "    dados = []\n",
    "\n",
    "    for ticker, tipo in lista_tickers:\n",
    "\n",
    "        # Definindo a URL com base no tipo de ativo\n",
    "        if tipo == 'Ação':\n",
    "            url = f\"https://investidor10.com.br/acoes/{ticker.lower()}/\"\n",
    "        elif tipo == 'FII':\n",
    "            url = f\"https://investidor10.com.br/fiis/{ticker.lower()}/\"\n",
    "        elif tipo == 'ETF':\n",
    "            url = f\"https://investidor10.com.br/etfs/{ticker.lower()}/\"\n",
    "        else:\n",
    "            url = None  # Tipo indefinido, pode ser tratado conforme necessário\n",
    "\n",
    "        valor = None\n",
    "\n",
    "        if url:\n",
    "            try:\n",
    "                response = requests.get(url, headers=headers, timeout=10)\n",
    "                response.raise_for_status()\n",
    "\n",
    "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "                # Escolhendo a classe correta com base no tipo de ativo\n",
    "                if tipo == 'Ação':\n",
    "                    cotacao_elemento = soup.find(\"div\", class_=\"_card-body\")\n",
    "                elif tipo == 'FII':\n",
    "                    cotacao_elemento = soup.find(\"div\", class_=\"compare-progress-bar primary\")\n",
    "                elif tipo == 'ETF':\n",
    "                    cotacao_elemento = soup.find(\"div\", class_=\"etfCurrentQuotation\")\n",
    "                else:\n",
    "                    cotacao_elemento = None  # Tipo indefinido, não procuramos\n",
    "\n",
    "                # Se encontrou o elemento, extrair e converter o valor\n",
    "                if cotacao_elemento:\n",
    "                    texto = cotacao_elemento.get_text(strip=True)\n",
    "                    valor = float(texto.replace(\"R$\", \"\").replace(\".\", \"\").replace(\",\", \".\"))\n",
    "                else:\n",
    "                    print(f\"Cotação não encontrada para {ticker} na URL: {url}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao obter {ticker} na URL: {url} | Erro: {e}\")\n",
    "\n",
    "        # Adicionando à lista de dados para o DataFrame\n",
    "        dados.append({\n",
    "            \"Ticker\": ticker,\n",
    "            \"Preço\": valor\n",
    "        })\n",
    "\n",
    "        sleep(1)  # pausa para evitar bloqueio\n",
    "\n",
    "    return pd.DataFrame(dados)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------- manutenção da fx\n",
    "# Essa estrutura abaixo servirá caso eu queira investigar a cotação de alguma url. Na realidade é a estrura inicial de\n",
    "# qualquer scrap desses que estou fazendo. Não faria sentido investigar urls com uma fx pronta.\n",
    "# Preciso editar as urls e outras coisas\n",
    "\n",
    "# import requests\n",
    "# import pandas as pd\n",
    "# from bs4 import BeautifulSoup\n",
    "# from time import sleep\n",
    "#\n",
    "# headers = {\n",
    "#     \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36\",\n",
    "#     \"Referer\": \"https://investidor10.com.br\"\n",
    "# }\n",
    "#\n",
    "# url = \"https://investidor10.com.br/fiis/hglg11\"\n",
    "#\n",
    "# response = requests.get(url, headers=headers, timeout=10)\n",
    "#\n",
    "# soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "#\n",
    "# # Procurar o elemento que contém a cotação (div com classe \"value\")\n",
    "# cotacao_elemento = soup.find(\"div\", class_=\"compare-progress-bar primary\")\n",
    "#\n",
    "# # soup\n",
    "#\n",
    "# cotacao_elemento\n",
    "#\n",
    "# texto = cotacao_elemento.get_text(strip=True)\n",
    "#\n",
    "# texto\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaf02db",
   "metadata": {},
   "source": [
    "### Money Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e379224",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def criar_df_cotacao_moneytimes(df_mov_financeiras):\n",
    "\n",
    "    # Obtendo os valores únicos da coluna 'ATIVO' e convertendo em uma lista\n",
    "    lista_tickers = df_mov_financeiras['Ativo'].unique().tolist()\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": \"https://www.moneytimes.com.br/\"\n",
    "    }\n",
    "\n",
    "    dados = []\n",
    "\n",
    "    for ticker in lista_tickers:\n",
    "\n",
    "        url = f\"https://www.moneytimes.com.br/cotacao/{ticker.lower()}/\"\n",
    "\n",
    "        valor = None\n",
    "\n",
    "        if url:\n",
    "            try:\n",
    "                response = requests.get(url, headers=headers, timeout=10)\n",
    "                response.raise_for_status()\n",
    "\n",
    "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "                cotacao_elemento = soup.find(\"div\", class_=\"valor\")\n",
    "\n",
    "                # Se encontrou o elemento, extrair e converter o valor\n",
    "                if cotacao_elemento:\n",
    "                    texto = cotacao_elemento.get_text(strip=True)\n",
    "                    valor = float(texto.replace(\"R$\", \"\").replace(\".\", \"\").replace(\",\", \".\"))\n",
    "                else:\n",
    "                    print(f\"Cotação não encontrada para {ticker} na URL: {url}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao obter {ticker} na URL: {url} | Erro: {e}\")\n",
    "\n",
    "                # Adicionando à lista de dados para o DataFrame\n",
    "            dados.append({\n",
    "                \"Ticker\": ticker,\n",
    "                \"Preço\": valor\n",
    "            })\n",
    "\n",
    "            sleep(1)  # pausa para evitar bloqueio\n",
    "\n",
    "    return pd.DataFrame(dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e8f92f",
   "metadata": {},
   "source": [
    "### Satus Invest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c18451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lista_manual_tickers = ['BBAS3', 'TAEE11', 'BRBI11', 'CSMG3', 'PETR4', 'VALE3', 'BBSE3', 'ISAE4', 'HASH11', 'IVVB11',\n",
    "# #                         'MXRF11', 'HGLG11', 'MXRF11', 'BTLG11', 'GARE11', 'GGRC11', 'RECR11', 'CPTS11', 'HSLG11',\n",
    "# #                         'XPLG11', 'XPML11', 'GTWR11', 'TAEE3', 'SAPR4', 'ITSA4']\n",
    "#\n",
    "# # -------------------------------------------------------------------------------------------------------------------\n",
    "# Cada tipo de ativo tem uma url diferente\n",
    "# Funciona no ambiente local, mas dá erro na nuvem\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def criar_df_cotacao_statusinvest(df_mov_financeiras):\n",
    "\n",
    "    # Obtendo os valores únicos da coluna 'ATIVO' e convertendo em uma lista de tuplas (ticker, tipo)\n",
    "    lista_tickers = df_mov_financeiras[['Ativo', 'Tipo de Ativo']].drop_duplicates().values.tolist()\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "        \"Referer\": \"https://statusinvest.com.br\"\n",
    "    }\n",
    "\n",
    "    dados = []\n",
    "\n",
    "    for ticker, tipo in lista_tickers:\n",
    "\n",
    "        # Definindo a URL com base no tipo de ativo\n",
    "        if tipo == 'Ação':\n",
    "            url = f\"https://statusinvest.com.br/acoes/{ticker.lower()}\"\n",
    "        elif tipo == 'FII':\n",
    "            url = f\"https://statusinvest.com.br/fundos-imobiliarios/{ticker.lower()}\"\n",
    "        elif tipo == 'ETF':\n",
    "            url = f\"https://statusinvest.com.br/etfs/{ticker.lower()}\"\n",
    "        else:\n",
    "            url = None  # Tipo indefinido, pode ser tratado conforme necessário\n",
    "\n",
    "        valor = None\n",
    "\n",
    "        if url:\n",
    "            try:\n",
    "                response = requests.get(url, headers=headers, timeout=10)\n",
    "                response.raise_for_status()\n",
    "\n",
    "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "                # Procurar o primeiro elemento com classe que contém a cotação\n",
    "                cotacao_elemento = soup.find(\"strong\", {\"class\": \"value\"})\n",
    "\n",
    "                if cotacao_elemento:\n",
    "                    texto = cotacao_elemento.get_text(strip=True)\n",
    "                    valor = float(texto.replace(\"R$\", \"\").replace(\".\", \"\").replace(\",\", \".\"))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Tentativa falhou para {ticker} na URL: {url} | Erro: {e}\")\n",
    "\n",
    "        # Adicionando à lista de dados para o DataFrame\n",
    "        dados.append({\n",
    "            \"Ticker\": ticker,\n",
    "            \"Preço\": valor\n",
    "        })\n",
    "\n",
    "        sleep(1)  # pausa para evitar bloqueio\n",
    "\n",
    "    return pd.DataFrame(dados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ebfa76",
   "metadata": {},
   "source": [
    "### Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a272c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sempre funcionou localmente. Assim que implementei na nuvem ela funcionou, mas depois de alguns dias testando,\n",
    "# começou a travar na nuvem e depois travou local também, tanto no projeto web quanto no local.\n",
    "\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "def criar_df_cotacao_yf(df_mov_financeiras):\n",
    "\n",
    "    lista_tickers = df_mov_financeiras['Ativo'].unique().tolist()\n",
    "\n",
    "    # Acrescentando \".SA\" a cada elemento da lista e ordenando para que fique na sequência padrão.\n",
    "    lista_tickers_yf = [ativo + \".SA\" for ativo in sorted(lista_tickers)]\n",
    "\n",
    "    data_api = '2025-05-15' # Se for usar, precisa deixar isso dinâmico.\n",
    "\n",
    "    df_cotacao_yf = yf.download( # yf.download não precisa de tratamento caso não encontre um ticker, pois ele preenche None e cotinua funcionando.\n",
    "        lista_tickers_yf,\n",
    "        start=data_api,\n",
    "        auto_adjust=False, # Se for cruzar dados c/ div em separado, deixar auto_adjust=False é melhor, senão conta o div duas vezes.\n",
    "        progress=False, # barra de progresso\n",
    "    )['Close']  # Escolhe coluna\n",
    "\n",
    "    return df_cotacao_yf\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------- Mesma estrutura da fx acima, mas pega 1 cotação por vez\n",
    "# import yfinance as yf\n",
    "# import pandas as pd\n",
    "# import time\n",
    "#\n",
    "# def criar_df_cotacao_yf(df_mov_financeiras):\n",
    "#     lista_tickers = df_mov_financeiras['Ativo'].unique().tolist()\n",
    "#\n",
    "#     # Acrescentando \".SA\" a cada elemento da lista e ordenando para que fique na sequência padrão.\n",
    "#     lista_tickers_yf = [ativo + \".SA\" for ativo in sorted(lista_tickers)]\n",
    "#\n",
    "#     data_api = '2025-05-15'  # Se for usar, precisa deixar isso dinâmico.\n",
    "#\n",
    "#     # DataFrame vazio para armazenar os dados\n",
    "#     df_cotacao_yf = pd.DataFrame()\n",
    "#\n",
    "#     for ticker in lista_tickers_yf:\n",
    "#         try:\n",
    "#             df_ticker = yf.download(\n",
    "#                 ticker,\n",
    "#                 start=data_api,\n",
    "#                 auto_adjust=False,\n",
    "#                 progress=False,\n",
    "#             )['Close']\n",
    "#\n",
    "#             df_cotacao_yf[ticker] = df_ticker  # adiciona como nova coluna\n",
    "#\n",
    "#         except Exception as e:\n",
    "#             print(f\"Erro ao baixar {ticker}: {e}\")\n",
    "#\n",
    "#         time.sleep(2)  # pausa de 2 segundos entre os downloads\n",
    "#\n",
    "#     return df_cotacao_yf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4b54f5",
   "metadata": {},
   "source": [
    "### Não lembro porque não deixei salva a fx que pega a cotação da fonte \"Fundamentos\". Provavelmente ela não achava Etfs ou algo assim. No projeto antigo Carteira1 eu devo ter um codigo que puxa a tabela completa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
